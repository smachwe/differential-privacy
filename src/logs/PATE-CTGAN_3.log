using loss cross_entropy and regularization dragan
eps: 0.189173 	 G: 3.654234 	 D: 1.036358
eps: 0.620118 	 G: 4.123738 	 D: 1.378363
eps: 0.879937 	 G: 4.134215 	 D: 1.480006
eps: 1.080481 	 G: 4.273053 	 D: 1.309181
eps: 1.250236 	 G: 4.066880 	 D: 1.248218
eps: 1.400618 	 G: 3.952754 	 D: 1.438482
eps: 1.536692 	 G: 3.764162 	 D: 1.274270
eps: 1.662492 	 G: 3.623842 	 D: 1.194619
eps: 1.779878 	 G: 3.619332 	 D: 1.184812
eps: 1.890824 	 G: 3.326250 	 D: 1.138158
eps: 1.995648 	 G: 3.315785 	 D: 1.222569
